# DSPy Project - Term Definition Generator

## ğŸ“– What is DSPy?

**DSPy (Declarative Self-Improving Python)** is a framework for building LLM systems without manually writing prompts.

Instead of prompt engineering, you:
- Define inputs and outputs
- Provide training examples
- Define a quality metric
- Let DSPy automatically generate and optimize prompts

### Prompts are Learned Artifacts

In DSPy, **prompts are not written** â€” they are learned automatically from your data and metrics.

---

## ğŸ¤” Why DSPy Exists

Traditional prompt engineering has serious problems:

- âŒ **Prompts are brittle** - Small wording changes break behavior
- âŒ **Improvements are manual** and non-reproducible
- âŒ **No clear evaluation** or optimization loop

DSPy was created to solve this by **treating prompts like trainable parameters**, similar to weights in machine learning.

---

## âœ¨ What DSPy Does

DSPy:
- âœ… Tries multiple prompt variants internally
- âœ… Uses training examples as supervision
- âœ… Evaluates each prompt using a metric
- âœ… Automatically selects the best performing prompt

**You never directly control prompt wording.**

---

## ğŸš« What DSPy Is NOT

DSPy is **NOT**:
- âŒ A chatbot framework
- âŒ A UI or frontend tool
- âŒ An agent framework
- âŒ A LangChain replacement
- âŒ A tool for "better writing"

**DSPy is a backend LLM systems engineering framework.**

---

## ğŸ¯ Project Goal

In this project:
- User provides a **term**
- System returns a **clear and correct definition**
- **No prompt is written manually**

---

## ğŸ”§ Project Structure

```
dspy-project/
â”‚
â”œâ”€â”€ README.md              # Project documentation
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ .env                   # API keys (git ignore)
â”œâ”€â”€ main.py                # Entry point
â”‚
â”œâ”€â”€ dspy_program/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ signature.py       # Input/Output definitions
â”‚   â”œâ”€â”€ program.py         # DSPy modules (Predict)
â”‚   â””â”€â”€ optimizer.py       # Optimization logic
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.py           # Training examples
â”‚   â”œâ”€â”€ dev.py             # Validation data
â”‚   â””â”€â”€ test.py            # Test data
â”‚
â””â”€â”€ metrics/
    â””â”€â”€ evaluation.py      # Quality metrics
```

This structure is simple, clean, and production-friendly.

---

## ğŸ“‹ Requirements

- Python 3.9+
- Ollama (free local LLM) or OpenAI API key
- Internet connection

### Install Dependencies

```bash
pip install -r requirements.txt
```

### Install Ollama (Free Option)

```bash
# Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Download Llama model
ollama pull llama3.2
```

---

## ğŸ› ï¸ Step-by-Step Implementation

### Step 1: Define the Signature (Input / Output)

```python
# dspy_program/signature.py
import dspy

class DefineTerm(dspy.Signature):
    """Given a term, provide its definition."""
    
    term = dspy.InputField()
    definition = dspy.OutputField()
```

**Signature rules:**
- Only input and output fields
- No instructions
- No prompt language
- **Signature defines the contract, not behavior**

---

### Step 2: Create the Program

```python
# dspy_program/program.py
import dspy
from .signature import DefineTerm

def get_program():
    return dspy.ChainOfThought(DefineTerm)
```

**Use:**
- `Predict` for simple tasks
- `ChainOfThought` for reasoning tasks (âœ… **Currently using**)

**Why Chain of Thought?**
- ğŸ§  Makes the model think step-by-step
- ğŸ“ˆ Improves accuracy for complex definitions
- ğŸ” Provides reasoning transparency
- âœ¨ Better quality outputs

---

### Step 3: Provide Training Data

```python
# data/train.py
import dspy

trainset = [
    dspy.Example(
        term="API",
        definition="An API is an interface that allows software systems to communicate."
    ).with_inputs("term"),

    dspy.Example(
        term="Neural Network",
        definition="A neural network is a computational model inspired by the human brain."
    ).with_inputs("term")
]
```

**DSPy learns from inputâ€“output examples, not from prompts.**

---

### Step 4: Define the Evaluation Metric

```python
# metrics/evaluation.py
def definition_match(example, prediction, trace=None):
    return example.definition.strip().lower() == prediction.definition.strip().lower()
```

**The metric decides:**
- Which output is good
- Which prompt performs best

âš ï¸ **Weak metrics produce weak systems.**

---

### Step 5: Optimize the Program

```python
# dspy_program/optimizer.py
import dspy
from metrics.evaluation import definition_match

def optimize_program(program, trainset):
    optimizer = dspy.BootstrapFewShot(metric=definition_match)
    return optimizer.compile(program, trainset=trainset)
```

**This is where DSPy:**
- Tries multiple prompts
- Evaluates them
- Selects the best one automatically

---

### Step 6: Run the System

```python
# main.py
import dspy
import os
from dotenv import load_dotenv
from dspy_program.program import get_program
from dspy_program.optimizer import optimize_program
from data.train import trainset

load_dotenv()

# Configure with free Ollama model
dspy.configure(
    lm=dspy.LM(model="ollama/llama3.2")
)

program = get_program()
optimized_program = optimize_program(program, trainset)

result = optimized_program(term="Artificial Intelligence")

# Print results
print(f"\nDefinition: {result.definition}")

# If using ChainOfThought, you can also see the reasoning
if hasattr(result, 'rationale'):
    print(f"Reasoning: {result.rationale}")
```

---

## ğŸ”„ Complete DSPy Flow (One Line)

```
Signature â†’ Program (ChainOfThought) â†’ Data â†’ Metric â†’ Optimizer â†’ Learned Prompt
```

**Prompts are outputs, not inputs.**

---

## â–¶ï¸ How to Run

```bash
cd dspy-project
python3 main.py
```

### Output Example:
```
==================================================
TERM: Artificial Intelligence
==================================================

Definition: Artificial Intelligence (AI) refers to the development 
of computer systems that can perform tasks that would typically 
require human intelligence, such as understanding language, 
recognizing images, and making decisions.
==================================================
```

**With Chain of Thought**, the model reasons step-by-step internally before generating the final definition, resulting in more accurate and well-structured outputs.

---

## âœ… What You SHOULD Do in DSPy

- âœ… Define clear input and output fields
- âœ… Provide real, representative examples
- âœ… Design strong evaluation metrics
- âœ… Think in terms of optimization, not wording

---

## âŒ What You Should NOT Do in DSPy

- âŒ Do not write prompts
- âŒ Do not tweak wording manually
- âŒ Do not put instructions inside signatures
- âŒ Do not expect good results without data
- âŒ Do not use DSPy for simple chatbots

---

## ğŸ’¡ Key Mental Model

> **Anything you would normally put into a prompt,  
> in DSPy you put into data or metrics.**

---

## ğŸ“ Final Summary

**DSPy is not prompt engineering.  
DSPy is LLM systems engineering.**

If you care about:
- âœ… **Accuracy**
- âœ… **Reproducibility**
- âœ… **Scalability**

**DSPy is the right tool.**

---

## ğŸ”‘ Features

âœ… **Completely Free** - Uses Ollama local model (no API costs)  
âœ… **Automatic Optimization** - Learns best prompts from examples  
âœ… **Type-safe** - Input/Output signatures clearly defined  
âœ… **Modular Design** - Clean, production-ready structure  
âœ… **Well Documented** - Detailed comments in every file  

---

## ğŸ› ï¸ Technologies Used

- **DSPy** - Language Model programming framework
- **Ollama** - Local LLM inference (Llama 3.2 model)
- **Python-dotenv** - Environment variables management

---

## ğŸ“Š Project Status

âœ… Project structure created  
âœ… All modules implemented  
âœ… Free LLM integrated (Ollama)  
âœ… Working end-to-end  
âœ… Fully documented with comments  

---

## ğŸ¤ Contributing

Feel free to contribute with issues and improvements on GitHub!

---

**Made with DSPy & Ollama ğŸš€**

**Written By**: Riti Rai

