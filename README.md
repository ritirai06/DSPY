# DSPy Project - Term Definition Generator

## ğŸ“– What is DSPy?

**DSPy (Declarative Self-Improving Python)** is a framework for building LLM systems without manually writing prompts.

Instead of prompt engineering, you:
- Define inputs and outputs
- Provide training examples
- Define a quality metric
- Let DSPy automatically generate and optimize prompts

### Prompts are Learned Artifacts

In DSPy, **prompts are not written** â€” they are learned automatically from your data and metrics.

---

## ğŸ¤” Why DSPy Exists

Traditional prompt engineering has serious problems:

- âŒ **Prompts are brittle** - Small wording changes break behavior
- âŒ **Improvements are manual** and non-reproducible
- âŒ **No clear evaluation** or optimization loop

DSPy was created to solve this by **treating prompts like trainable parameters**, similar to weights in machine learning.

---

## âœ¨ What DSPy Does

DSPy:
- âœ… Tries multiple prompt variants internally
- âœ… Uses training examples as supervision
- âœ… Evaluates each prompt using a metric
- âœ… Automatically selects the best performing prompt

**You never directly control prompt wording.**

---

## ğŸš« What DSPy Is NOT

DSPy is **NOT**:
- âŒ A chatbot framework
- âŒ A UI or frontend tool
- âŒ An agent framework
- âŒ A LangChain replacement
- âŒ A tool for "better writing"

**DSPy is a backend LLM systems engineering framework.**

---

## ğŸ¯ Project Goal

In this project:
- User provides a **term**
- System returns a **clear and correct definition**
- **No prompt is written manually**

---

## ğŸ”§ Project Structure

```
dspy-project/
â”‚
â”œâ”€â”€ README.md              # Project documentation
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ .env                   # API keys (git ignore)
â”œâ”€â”€ main.py                # Entry point
â”‚
â”œâ”€â”€ dspy_program/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ signature.py       # Input/Output definitions
â”‚   â”œâ”€â”€ program.py         # DSPy modules (Predict)
â”‚   â””â”€â”€ optimizer.py       # Optimization logic
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.py           # Training examples
â”‚   â”œâ”€â”€ dev.py             # Validation data
â”‚   â””â”€â”€ test.py            # Test data
â”‚
â””â”€â”€ metrics/
    â””â”€â”€ evaluation.py      # Quality metrics
```

This structure is simple, clean, and production-friendly.

---

## ğŸ“‹ Requirements

- Python 3.9+
- Ollama (free local LLM) or OpenAI API key
- Internet connection

### Install Dependencies

```bash
pip install -r requirements.txt
```

### Install Ollama (Free Option)

```bash
# Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Download Llama model
ollama pull llama3.2
```

---

## ğŸ› ï¸ Step-by-Step Implementation

### Step 1: Define the Signature (Input / Output)

```python
# dspy_program/signature.py
import dspy

class DefineTerm(dspy.Signature):
    """Given a term, provide its definition."""
    
    term = dspy.InputField()
    definition = dspy.OutputField()
```

**Signature rules:**
- Only input and output fields
- No instructions
- No prompt language
- **Signature defines the contract, not behavior**

---

### Step 2: Create the Program

```python
# dspy_program/program.py
import dspy
from .signature import DefineTerm

def get_program():
    return dspy.Predict(DefineTerm)
```

**Use:**
- `Predict` for simple tasks
- `ChainOfThought` for reasoning tasks

---

### Step 3: Provide Training Data

```python
# data/train.py
import dspy

trainset = [
    dspy.Example(
        term="API",
        definition="An API is an interface that allows software systems to communicate."
    ).with_inputs("term"),

    dspy.Example(
        term="Neural Network",
        definition="A neural network is a computational model inspired by the human brain."
    ).with_inputs("term")
]
```

**DSPy learns from inputâ€“output examples, not from prompts.**

---

### Step 4: Define the Evaluation Metric

```python
# metrics/evaluation.py
def definition_match(example, prediction, trace=None):
    return example.definition.strip().lower() == prediction.definition.strip().lower()
```

**The metric decides:**
- Which output is good
- Which prompt performs best

âš ï¸ **Weak metrics produce weak systems.**

---

### Step 5: Optimize the Program

```python
# dspy_program/optimizer.py
import dspy
from metrics.evaluation import definition_match

def optimize_program(program, trainset):
    optimizer = dspy.BootstrapFewShot(metric=definition_match)
    return optimizer.compile(program, trainset=trainset)
```

**This is where DSPy:**
- Tries multiple prompts
- Evaluates them
- Selects the best one automatically

---

### Step 6: Run the System

```python
# main.py
import dspy
import os
from dotenv import load_dotenv
from dspy_program.program import get_program
from dspy_program.optimizer import optimize_program
from data.train import trainset

load_dotenv()

# Configure with free Ollama model
dspy.configure(
    lm=dspy.LM(model="ollama/llama3.2")
)

program = get_program()
optimized_program = optimize_program(program, trainset)

result = optimized_program(term="Artificial Intelligence")
print(result.definition)
```

---

## ğŸ”„ Complete DSPy Flow (One Line)

```
Signature â†’ Program â†’ Data â†’ Metric â†’ Optimizer â†’ Learned Prompt
```

**Prompts are outputs, not inputs.**

---

## â–¶ï¸ How to Run

```bash
cd dspy-project
python3 main.py
```

### Output Example:
```
Artificial intelligence is the development of computer systems 
able to perform tasks that typically require human intelligence, 
such as visual perception, speech recognition, decision-making, 
and language translation.
```

---

## âœ… What You SHOULD Do in DSPy

- âœ… Define clear input and output fields
- âœ… Provide real, representative examples
- âœ… Design strong evaluation metrics
- âœ… Think in terms of optimization, not wording

---

## âŒ What You Should NOT Do in DSPy

- âŒ Do not write prompts
- âŒ Do not tweak wording manually
- âŒ Do not put instructions inside signatures
- âŒ Do not expect good results without data
- âŒ Do not use DSPy for simple chatbots

---

## ğŸ’¡ Key Mental Model

> **Anything you would normally put into a prompt,  
> in DSPy you put into data or metrics.**

---

## ğŸ“ Final Summary

**DSPy is not prompt engineering.  
DSPy is LLM systems engineering.**

If you care about:
- âœ… **Accuracy**
- âœ… **Reproducibility**
- âœ… **Scalability**

**DSPy is the right tool.**

---

## ğŸ”‘ Features

âœ… **Completely Free** - Uses Ollama local model (no API costs)  
âœ… **Automatic Optimization** - Learns best prompts from examples  
âœ… **Type-safe** - Input/Output signatures clearly defined  
âœ… **Modular Design** - Clean, production-ready structure  
âœ… **Well Documented** - Detailed comments in every file  

---

## ğŸ› ï¸ Technologies Used

- **DSPy** - Language Model programming framework
- **Ollama** - Local LLM inference (Llama 3.2 model)
- **Python-dotenv** - Environment variables management

---

## ğŸ“Š Project Status

âœ… Project structure created  
âœ… All modules implemented  
âœ… Free LLM integrated (Ollama)  
âœ… Working end-to-end  
âœ… Fully documented with comments  

---

## ğŸ¤ Contributing

Feel free to contribute with issues and improvements on GitHub!

---

**Made with DSPy & Ollama ğŸš€**

Prompts are learned artifacts

Why DSPy Exists

Traditional prompt engineering has serious problems:

Prompts are brittle

Small wording changes break behavior

Improvements are manual and non-reproducible

No clear evaluation or optimization loop

DSPy was created to solve this by treating prompts like trainable parameters, similar to weights in machine learning.

What DSPy Does

DSPy:

Tries multiple prompt variants internally

Uses training examples as supervision

Evaluates each prompt using a metric

Automatically selects the best performing prompt

You never directly control prompt wording.

What DSPy Is NOT

DSPy is NOT:

A chatbot framework

A UI or frontend tool

An agent framework

A LangChain replacement

A tool for â€œbetter writingâ€

DSPy is a backend LLM systems engineering framework.

Project Goal (Example)

In this project:

User provides a term

System returns a clear and correct definition

No prompt is written manually

Project Structure
dspy-project/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ main.py
â”‚
â”œâ”€â”€ dspy_program/
â”‚   â”œâ”€â”€ signature.py
â”‚   â”œâ”€â”€ program.py
â”‚   â””â”€â”€ optimizer.py
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ train.py
â”‚
â””â”€â”€ metrics/
    â””â”€â”€ evaluation.py


This structure is simple, clean, and production-friendly.

Requirements

Python 3.9+

OpenAI or Anthropic API key

Internet connection

Install dependencies
pip install dspy-ai

Step 1: Define the Signature (Input / Output)
# dspy_program/signature.py
import dspy

class DefineTerm(dspy.Signature):
    term: str
    definition: str


Signature rules:

Only input and output fields

No instructions

No prompt language

Signature defines the contract, not behavior.

Step 2: Create the Program
# dspy_program/program.py
import dspy
from .signature import DefineTerm

def get_program():
    return dspy.Predict(DefineTerm)


Use:

Predict for simple tasks

ChainOfThought for reasoning tasks

Step 3: Provide Training Data
# data/train.py
import dspy

trainset = [
    dspy.Example(
        term="API",
        definition="An API is an interface that allows software systems to communicate."
    ).with_inputs("term"),

    dspy.Example(
        term="Database",
        definition="A database stores and manages structured data."
    ).with_inputs("term")
]


DSPy learns from inputâ€“output examples, not from prompts.

Step 4: Define the Evaluation Metric
# metrics/evaluation.py
def definition_match(example, prediction):
    return example.definition.lower() in prediction.definition.lower()


The metric decides:

Which output is good

Which prompt performs best

Weak metrics produce weak systems.

Step 5: Optimize the Program
# dspy_program/optimizer.py
import dspy
from metrics.evaluation import definition_match

def optimize_program(program, trainset):
    optimizer = dspy.BootstrapFewShot(metric=definition_match)
    return optimizer.compile(program, trainset=trainset)


This is where DSPy:

Tries multiple prompts

Evaluates them

Selects the best one automatically

Step 6: Run the System
# main.py
import dspy
from dspy_program.program import get_program
from dspy_program.optimizer import optimize_program
from data.train import trainset

dspy.configure(
    lm=dspy.OpenAI(model="gpt-4o-mini")
)

program = get_program()
optimized_program = optimize_program(program, trainset)

result = optimized_program(term="Artificial Intelligence")
print(result.definition)

Complete DSPy Flow (One Line)
Signature â†’ Program â†’ Data â†’ Metric â†’ Optimizer â†’ Learned Prompt


Prompts are outputs, not inputs.

What You SHOULD Do in DSPy

Define clear input and output fields

Provide real, representative examples

Design strong evaluation metrics

Think in terms of optimization, not wording

What You Should NOT Do in DSPy

Do not write prompts

Do not tweak wording manually

Do not put instructions inside signatures

Do not expect good results without data

Do not use DSPy for simple chatbots

Key Mental Model

Anything you would normally put into a prompt,
in DSPy you put into data or metrics.

Final Summary

DSPy is not prompt engineering.
DSPy is LLM systems engineering.

If you care about:

Accuracy

Reproducibility

Scalability

DSPy is the right tool.# DSPY
# DSPY
